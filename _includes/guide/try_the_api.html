<p>
	To get you started with BCDA, we provide the minimum steps to access data in the sandbox. Using the four cURL commands below, you should be able to walk through the standard process of retrieving data from the API:
</p>
<ol>
	<li>Obtain an access token: How do I show the API that I can receive this data?</li>
	<li>Start a job to acquire data: How do I tell the API to get my data?</li>
	<li>Check the job status: How do I check when the API is done getting my data?</li>
	<li>Download the data: How do I get my data once it is done?</li>
</ol>
<p>
	All requests for BCDA data follow this four step process, as do other APIs following the Bulk FHIR specifications.
</p>
<p>
	For more detail for each of these steps and specific information for retrieving production data, see the <a href=/build.html target="_self" class="in-text__link"> Building Your Application</a> page. For this short demo, follow along in your Terminal window or through an application such as Postman. PowerShell users will need to replace backslash characters \ with backticks ` to properly escape the $export operation.
</p>

<h2>
	BCDA Synthetic Data
</h2>
<p>
	BCDA has provided nine synthetic data sample sets for use. Because all of these data sets are synthetic, they can be accessed without any BCDA production environment credentials or approval by BCDA.
</p>

<h3>
	Simple Datasets - Five Sizes
</h3>
<p>
	Five of these datasets are simple approximations of BCDA data designed for model entities to test the stress of retrieving and downloading large data files into their internal ingestion processes. These datasets are offered in various sizes so that organizations can test files with a number of beneficiaries that best matches the needs of their organization (the datasets range from 50 to 30,000 synthetic beneficiaries). However, the data in these API payloads will not reflect the distribution of disease and demographic information you might expect from production data.
</p>

<div>
	{% include guide/credentials.html %}
</div>

<h3>
	Advanced Datasets  - Two Sizes
</h3>
<p>
	These two datasets are designed to offer data that is a more accurate representation of BCDA production data. They follow BCDA’s Bulk FHIR format and should contain a more realistic distribution of disease and demographic information. The advanced datasets are offered in two sizes: Extra Small (100 beneficiaries) and Large (10,000 beneficiaries). We suggest using the Extra-Small Model Entity file to simply view and begin to understand the format of BCDA data. You may want to use the Large dataset for more in-depth exploration of the data or early load testing of your systems.
</p>

<div>
	{% include guide/adv_credentials.html %}
</div>

<h3>
  Partially Adjudicated Claims Datasets - Two Sizes
</h3>
<p>
       These last two datasets are examples representing data from our Partially Adjudicated Claims data. They include the additional FHIR® resources Claim and ClaimResponse for Partially Adjudicated Claims data. The Partially adjudicated claims data requires BCDA v2.
</p>
<ol>
  <li><strong>Claim:</strong> Contains information about professional and institutional claims that providers submit for payment, including the services that beneficiaries receive.</li>
  <li><strong>ClaimResponse:</strong> Provides information about a claim's adjudication status and results.</li>
</ol>

<h3>Sample Credentials</h3>
<div>
	{% include guide/bcda_enhancement_credentials.html %}
</div>


<h2>
	Step 1: Obtain an Access Token
</h2>
<p>
	For this demonstration, we will provide sample API credentials to the sandbox environment. We will be using the sample
	credentials for an Extra-Small Model Entity (50 beneficiaries). Feel free to follow along with any of the sample credentials.
</p>
<p>
	Our credentials come in two pieces: a Client ID and a Client Secret. We will submit these two pieces to the API. Notice that the credentials are included in one of the headers (--user). You must use this format: --user {insert client id}{insert colon}{insert client secret}.
</p>
<h3>
	Sample cURL Command to Submit Credentials for an Access Token
</h3>
<pre><code>curl -d "" -X POST "https://sandbox.bcda.cms.gov/auth/token" \
	--user {{site.data.credentials.sandbox.extra_small.client_id}}:{{site.data.credentials.sandbox.extra_small.client_secret}} \
	-H "accept: application/json"</code></pre>

<h3>
	Response Example after Submitting Credentials for an Access Token
</h3>
<p>
	We have a key (an access token) to interact with the API! It expires after 20 minutes.
</p>
<p>
	If the request was successful, we will receive a response with the code 200 containing a few headers. The first header ("access token") contains a long string of characters. This is our access token which must be attached to all of our other requests to the API.
</p>
<pre><code>{
"access_token": "<span style="color: #046B99;">{access_token}</span>",
"token_type":"bearer"
}</code></pre>








<h2>
	Step 2: Start a Job
</h2>
<p>
	With our new access token, we are able to make more requests to the API. We will now tell the server to deliver our data.
</p>
<p>
	In this example, we requested data from the /Patient endpoint with no date filter (no _since parameter) and no specified resource type (no _type parameter). We included the long string of characters from the previous step (our access token) in the authorization header (-H "Authorization: Bearer "). Notice that we needed to include the word "Bearer" followed by a space before the access token. We also added "-i" in order to see the Job ID.
</p>
	<h3>
		Sample cURL Command to Start a Job
	</h3>
<pre><code>curl -X GET "https://sandbox.bcda.cms.gov/api/v2/Group/all/\$export" \
	-H "accept: application/fhir+json" \
	-H "Prefer: respond-async" \
	-H "Authorization: Bearer <span style="color: #046B99;">{access_token}</span>" \
	-i</code></pre>

<h3>Response Example after Starting a Job</h3>
<p>
	We've now started a data export job. It may take some time to complete, depending on how much claims data is contained in our job.
</p>
<p>
	If the request was successful, we will receive a response with the code 202 containing a few headers. One of the headers (Content-Location) will contain a URL. Notice that the URL ends in a number. This is the Job ID of the job we just started. In the next step, we will use this URL and Job ID to check if the server is done preparing our file(s).
</p>
<pre><code>202 Accepted
Content-Location: https://sandbox.bcda.cms.gov/api/v2/jobs/<span style="color: #046B99;">{job_id}</span>
</code></pre>









<H3>
	Step 3: Check the Job Status
</H3>
<p>
	Now that our job is in progress, we can check back in occasionally to see if it is finished. The data for our synthetic sandbox model entities should not take too long to compile.
</p>
<p>
	We will make a request to the API to check on our job. Notice the URL in the first line (curl -X GET "URL") is the same as the URL from the previous step in the Content-Location header.
</p>
<H4>
	Sample cURL Command to Check the Job Status
</H4>
<pre><code>curl -X GET "https://sandbox.bcda.cms.gov/api/v2/jobs/<span style="color: #046B99;">{job_id}</span>" \
	-H "accept: application/fhir+json" \
	-H "Authorization: Bearer <span style="color: #046B99;">{access_token}</span>"</code></pre>
<h4>
	Response Example after Checking on a Job
</h4>
<p>
	It looks like our job is finished and our data is ready to be downloaded.
</p>
<p>
	If the request was successful, and the job is finished, we will receive a response containing many headers. Some of these headers ("url") will contain a URL. Each of these URLs corresponds to a file containing claims data. We received five files: one for each resource type. We will use these URLs to download the data in the final step.
</p>
	<pre><code>{
  "transactionTime": "2021-12-09T20:44:01.705398Z",
  "request": "https://sandbox.bcda.cms.gov/api/v2/Patient/$export",
  "requiresAccessToken": true,
  "output": [
    {
      "type": "ExplanationOfBenefit",
      "url": "https://sandbox.bcda.cms.gov/data/42/afd22dfa-c239-4063-8882-eb2712f9f638.ndjson"
    },
    {
      "type": "Coverage",
      "url": "https://sandbox.bcda.cms.gov/data/42/f76a0b76-48ed-4033-aad9-d3eec37e7e83.ndjson"
    },
    {
      "type": "Patient",
      "url": "https://sandbox.bcda.cms.gov/data/42/f92dcf16-63a2-448e-a12a-3bf677f966ed.ndjson"
    },
    {
      "type": "Claim",
      "url": "https://sandbox.bcda.cms.gov/data/42/6397b6b8-5842-493a-9206-e68b2995c001.ndjson"
    },
    {
      "type": "ClaimResponse",
      "url": "https://sandbox.bcda.cms.gov/data/42/0a0b1312-e0a2-4284-a094-1b98bdd0de3c.ndjson"
    }
  ],
  "error": [],
  "JobID": 42
}</code></pre>




<H3>
	Step 4: Download the Data
</H3>
<p>
	The final step in the workflow is to download your data. Make another request to the API, this time using any of the URLs retrieved in the previous step. Each URL corresponds to a single file and will begin the download of that file. We will need to make three download requests to get all three of our files.
</p>
	<H4>
		Sample cURL Command to Download the Data
	</H4>
<pre><code>curl "<span style="color: #046B99;">{output_url}</span>" \
	-H "Authorization: Bearer <span style="color: #046B99;">{access_token}</span>" \
	-H "Accept-Encoding: gzip"
</code></pre>
<h4>
Response Example after Downloading the Data
</h4>
<p>
	<ol>
		<li><strong><a href="https://bcda.cms.gov/assets/data/ExplanationOfBenefit.ndjson" target="_blank" rel="noopener" class="in-text__link"> Explanation of Benefit</a></strong></li>
		<li><strong><a href="https://bcda.cms.gov/assets/data/Patient.ndjson" target="_blank" rel="noopener" class="in-text__link"> Patient</a></strong></li>
		<li><strong><a href="https://bcda.cms.gov/assets/data/Coverage.ndjson" target="_blank" rel="noopener" class="in-text__link"> Coverage</a></strong></li>
		<li><strong><a href="https://bcda.cms.gov/assets/data/Claim.ndjson" target="_blank" rel="noopener" class="in-text__link"> Claim</a></strong></li>
		<li><strong><a href="https://bcda.cms.gov/assets/data/ClaimResponse.ndjson" target="_blank" rel="noopener" class="in-text__link"> ClaimResponse</a></strong></li>
	</ol>
</p>






<H3>
	Congratulations!
</H3>
<p>
	If all of the steps above worked, you will now have files of synthetic beneficiary claims data on your local machine! You have walked through the process of proving your authentication to the API, starting a job to compile your data, checking on that job using its ID number, and downloading the results using the filenames. This four step process is universal for BCDA data requests (and many other Bulk FHIR workflows).
</p>	 
	Go to the <a href="/build.html" target="_self">Building Your Application page</a> to see how to download data for your organizations' real beneficiaries, download different combinations of Resource Types, filter data by date, and filter some beneficiary data by date while retrieving all data for others.
</p>
